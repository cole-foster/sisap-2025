{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdB0pBmjnzHA"
      },
      "source": [
        "# **SISAP 2025 Challenge: Data Preparation and Compression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ44rZt0D538"
      },
      "source": [
        "This notebook presents the initial steps of data preparation and compression for the SISAP 2025 challenge dataset.\n",
        "\n",
        "- **Section 1:** Loads the dataset `benchmark-dev-ccnews.h5` from the SISAP 2025 challenge repository on Hugging Face.\n",
        "\n",
        "- **Section 2:** Applies a rotation transformation to the original embeddings.\n",
        "\n",
        "- **Section 3:** Encodes the rotated embeddings into a more memory-efficient format. The resulting encoding is a dictionary containing four key elements:\n",
        "\n",
        "  1. **`packed_binary_matrix`**: A PyTorch tensor storing the index matrix packed in bytes. Since PyTorch does not support bit-level boolean tensors, the indices are packed byte-wise. This tensor has the same number of rows as the original embedding database, with packing performed along each row.\n",
        "\n",
        "  2. **`outliers`**: A tensor with fewer columns than the original embeddings, storing outlier values that correspond to zero entries in the index matrix.\n",
        "\n",
        "  3. **`avg_values`**: A one-dimensional tensor containing a small set of average values. The first element is zero; the subsequent elements correspond to average values. Each value in the index matrix maps directly to an index in `avg_values`, so a matrix entry of `i` corresponds to `avg_values[i]`.\n",
        "\n",
        "  4. **`og_shape_bin`**: Metadata used to correctly unpack the `packed_binary_matrix` back to its original shape.\n",
        "\n",
        "  Because the compressed elements are organized as tensors with uniform row sizes, this structure supports efficient partial decoding: an index can be built over the compressed dataset where only the specific embedding(s) required during a query are decoded on demand.\n",
        "\n",
        "- **Section 4:** Brute-force similarity search experiments to evaluate the recall@k performance of the proposed compression scheme.\n",
        "\n",
        "- **Section 5:** Results obtained for the best configuration.\n",
        "\n",
        "\n",
        "\n",
        "**Note:** The best recall values were obtained when using a 6-bit resolution for the index matrix and full dot product. Therefore, this notebook focuses on reporting the results for that configuration. However, all functions required to evaluate other bit resolutions are included and can be used for further experimentation.\n",
        "\n",
        "\n",
        "---\n",
        "*Notebook created by Scarlett Magdaleno-Gatica, Master's student in Computer Science at CICESE, for SISAP 2025 challenge. This is a preliminary version.*  \n",
        "*Date: June 02, 2025*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zStrEIPq7cWN"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMXw6dwp7cdt",
        "outputId": "b825b1d7-15d8-4986-9840-c0224661f07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (2.12.0)\n",
            "Collecting faiss-cpu\n",
            "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/53/45/7c85551025d9f0237d891b5cffdc5d4a366011d53b4b0a423b972cc52cea/faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: h5py in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (3.9.0)\n",
            "Requirement already satisfied: scikit-learn in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from datasets) (6.0)\n",
            "Collecting numpy>=1.17 (from datasets)\n",
            "  Obtaining dependency information for numpy>=1.17 from https://files.pythonhosted.org/packages/b3/dd/2238b898e51bd6d389b7389ffb20d7f4c10066d80351187ec8e303a5a475/numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: filelock in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: six in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
            "  Obtaining dependency information for numpy>=1.17 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy, faiss-cpu\n",
            "\u001b[33m  WARNING: The script f2py is installed in '/users/cfoste18/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
            "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
            "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
            "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-cpu-1.11.0 numpy-1.26.4\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: huggingface_hub in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: fsspec in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (2023.4.0)\n",
            "Requirement already satisfied: requests in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets faiss-cpu h5py scikit-learn\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-u8577tny6a"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HBsV1qkinnNe"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import faiss\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import precision_score\n",
        "from typing import Tuple\n",
        "from huggingface_hub import hf_hub_download\n",
        "from huggingface_hub import login\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcYEhID97mTA",
        "outputId": "e56e8654-3f28-47aa-8ff6-6743bec58e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "# results_dir = 'ntent/drive/MyDri/cove/Tesis/SISAP/Cache'\n",
        "# new_results_dir = '/content/drive/MyDrive/Tesis/SISAP/NewCache'\n",
        "\n",
        "# login_token = \"\"\n",
        "\n",
        "# # Iniciar sesión en Hugging Face\n",
        "# login(token=login_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrgvRENZotk9"
      },
      "source": [
        "## **1. Load Dataset from HuggingFace**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "1f2b7a04b43447bb8bdfe2836a5a0b9a",
            "88b0e98dbb0f45db846e59d2ba4abeec",
            "b0ce8f01c08046ed861da8f40a42dcf3",
            "00d14bb8e6074aeb9be2947ef8c5a050",
            "8ad5161fe6a046bc96b93e01b7ea85ec",
            "c982cd01cf684575913a63fc229aaa7e",
            "1990a08c47f340149acea81d2322b55f",
            "29fdf4c7be0d485ab81d007ef3dbd639",
            "bfc9229ef05e420f98c53b15d367cbd3",
            "2a09ba370b0b49d596e08824d8f678e9",
            "4d323be5b6e24e2fb652ff6215fa83f8"
          ]
        },
        "id": "0K9rfg1lotvV",
        "outputId": "3363c2d3-34ca-48fc-c283-2db0a609384e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Tuple' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_sisap_benchmark\u001b[39m(file_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Loads the benchmark file of vectors (train, itest/otest) and returns base and queries as PyTorch tensors.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tuple' is not defined"
          ]
        }
      ],
      "source": [
        "def load_sisap_benchmark(file_path: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Loads the benchmark file of vectors (train, itest/otest) and returns base and queries as PyTorch tensors.\n",
        "    \"\"\"\n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        print(\"Keys available in the file:\", list(f.keys()))\n",
        "\n",
        "        # Ensure the expected keys are present\n",
        "        if 'train' not in f or 'otest' not in f:\n",
        "            raise KeyError(\"Keys 'train' or 'otest' are not found in the file.\")\n",
        "        print(f\"original_dtype: {f['train'].dtype}\")\n",
        "\n",
        "        base = torch.tensor(np.array(f['train']))  # Training vectors (base)\n",
        "        queries = torch.tensor(np.array(f['otest']['queries']))  # Query vectors from the 'otest' group\n",
        "        dists = torch.tensor(np.array(f['otest']['dists']))  # Distances to nearest neighbors\n",
        "        knns = torch.tensor(np.array(f['otest']['knns']))  # Indices of nearest neighbors\n",
        "\n",
        "    return base, queries, dists, knns\n",
        "\n",
        "# Load benchmark and ground truth\n",
        "# file_benchmark_path = hf_hub_download(\n",
        "#     repo_id=\"sadit/SISAP2025\",                # dataset name\n",
        "#     filename=\"benchmark-dev-ccnews.h5\",       # file name\n",
        "#     repo_type=\"dataset\"                       # important: specify that it is a dataset\n",
        "# )\n",
        "\n",
        "file_benchmark_path = \"/users/cfoste18/data/cfoste18/knn-construction/data/ccnews/ccnews.h5\"\n",
        "base, queries, dists, knns = load_sisap_benchmark(file_benchmark_path)\n",
        "\n",
        "print(\"Base:\", base.shape)\n",
        "print(\"Queries:\", queries.shape)\n",
        "print(\"Ground truth dists:\", dists.shape)\n",
        "print(\"Ground truth knns:\", knns.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mlpwiCzo4bT"
      },
      "source": [
        "## **2. Rotate embeddings with random rotation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-wlsNRmno4nc"
      },
      "outputs": [],
      "source": [
        "def generate_rotation_matrix_Q(n, dtype=torch.float32):\n",
        "    \"\"\"\n",
        "    Generates an n x n rotation matrix Q using PyTorch and returns it as a PyTorch tensor.\n",
        "\n",
        "    The columns of Q are orthonormal vectors, and the matrix has a determinant of 1.\n",
        "\n",
        "    Args:\n",
        "        n (int): Size of the matrix.\n",
        "        dtype (torch.dtype): Desired dtype for the output rotation matrix (e.g., torch.float32, torch.float16).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Orthonormal rotation matrix Q as a PyTorch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a random matrix using PyTorch\n",
        "    random_matrix = torch.randn(n, n, dtype=dtype)\n",
        "\n",
        "    # Apply QR decomposition to obtain an orthonormal matrix Q\n",
        "    Q, R = torch.linalg.qr(random_matrix)\n",
        "\n",
        "    # Ensure that Q is a rotation matrix (det(Q) = 1)\n",
        "    det_Q = torch.det(Q)\n",
        "    if det_Q < 0:\n",
        "        # Adjust the sign of the last column to ensure det(Q) = 1\n",
        "        Q[:, -1] *= -1  # Multiply the last column by -1\n",
        "\n",
        "    return Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gt0DEItNpGHE"
      },
      "outputs": [],
      "source": [
        "# Generate the random rotation matrix\n",
        "n = base.shape[1]\n",
        "#Q = generate_rotation_matrix_Q(n)\n",
        "#torch.save(Q, os.path.join(results_dir, 'rotation_matrix.pt'))\n",
        "Q = torch.load(os.path.join(results_dir, 'rotation_matrix.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6kpsGOhpHtH",
        "outputId": "2933de58-36b7-488f-e4ef-c4430a144065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rotated Queries: torch.Size([11000, 384])\n",
            "Rotated Base: torch.Size([603664, 384])\n"
          ]
        }
      ],
      "source": [
        "rotated_queries = torch.matmul(queries, Q.T)\n",
        "rotated_base = torch.matmul(base, Q.T)\n",
        "\n",
        "print(f\"Rotated Queries: {rotated_queries.shape}\")\n",
        "print(f\"Rotated Base: {rotated_base.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HocesHpsLj"
      },
      "source": [
        "## **3. OrthoQuant compression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24bHgfdsKed"
      },
      "source": [
        "### Enconding Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RWkQuV7Hpsh5"
      },
      "outputs": [],
      "source": [
        "def orthoQuant_encode(D, lower_limit, upper_limit, num_bits):\n",
        "    dtype = D.dtype\n",
        "    device = D.device\n",
        "    B, N = D.shape\n",
        "    num_segments = 2**num_bits - 1\n",
        "    less_segments = num_segments // 2\n",
        "    more_segments = num_segments - less_segments\n",
        "\n",
        "    sorted_D, _ = torch.sort(D, dim=1)\n",
        "    l = sorted_D[:, lower_limit]\n",
        "    r = sorted_D[:, upper_limit]\n",
        "    l = torch.where(l > 0, -r.abs(), l)\n",
        "    r = torch.where(r < 0, l.abs(), r)\n",
        "\n",
        "    mask_l = D < l.unsqueeze(1)\n",
        "    mask_r = D > r.unsqueeze(1)\n",
        "\n",
        "    # Initial counts per row\n",
        "    counts_l = mask_l.sum(dim=1)\n",
        "    counts_r = mask_r.sum(dim=1)\n",
        "\n",
        "    # Expected values (we use the first one)\n",
        "    expected_l = counts_l[0]\n",
        "    expected_r = counts_r[0]\n",
        "\n",
        "    # Expand masks if necessary\n",
        "    mask_l = expand_mask_side(mask_l, counts_l, expected_l, sorted_D, D, side='left')\n",
        "    mask_r = expand_mask_side(mask_r, counts_r, expected_r, sorted_D, D, side='right')\n",
        "\n",
        "    # Recompute counts to ensure uniformity\n",
        "    counts_l = mask_l.sum(dim=1)\n",
        "    counts_r = mask_r.sum(dim=1)\n",
        "\n",
        "    assert torch.all(counts_l == expected_l), \"Left mask uniformity was not achieved\"\n",
        "    assert torch.all(counts_r == expected_r), \"Right mask uniformity was not achieved\"\n",
        "\n",
        "    mask_og = mask_l | mask_r\n",
        "\n",
        "    # Ensure all vectors have the same number of out-of-range values\n",
        "    counts = mask_og.sum(dim=1)\n",
        "    assert torch.all(counts == counts[0]), f\"Vectors do not have the same number of out-of-range values! {counts}\"\n",
        "\n",
        "    non_zero_elements_tensor = D[mask_og].view(B, -1)\n",
        "\n",
        "    mask_in_range = ~mask_og\n",
        "    mask_neg = (l.unsqueeze(1) <= D) & (D < 0) & mask_in_range\n",
        "    mask_pos = (0 <= D) & (D <= r.unsqueeze(1)) & mask_in_range\n",
        "\n",
        "    # Fixed number of segments\n",
        "    count_neg = mask_neg[0].sum()\n",
        "    count_pos = mask_pos[0].sum()\n",
        "    num_segments_l = more_segments if count_neg > count_pos else less_segments\n",
        "    num_segments_r = num_segments - num_segments_l\n",
        "\n",
        "    neg_edges = torch.linspace(-1, 0, num_segments_l + 1, device=device).view(1, -1)\n",
        "    pos_edges = torch.linspace(0, 1, num_segments_r + 1, device=device).view(1, -1)\n",
        "\n",
        "    # Scale edges based on thresholds\n",
        "    neg_edges_scaled = l.view(-1, 1) * (-1 * neg_edges)\n",
        "    pos_edges_scaled = r.view(-1, 1) * pos_edges\n",
        "\n",
        "    # Initialization\n",
        "    avg_values = torch.zeros((B, num_segments), dtype=dtype, device=device)\n",
        "\n",
        "    for seg_idx in range(num_segments_l):\n",
        "        lower = neg_edges_scaled[:, seg_idx].unsqueeze(1)\n",
        "        upper = neg_edges_scaled[:, seg_idx + 1].unsqueeze(1)\n",
        "        seg_mask = (D >= lower) & (D < upper) & mask_neg\n",
        "        seg_vals = torch.where(seg_mask, D, torch.zeros_like(D))\n",
        "        counts = seg_mask.sum(dim=1)\n",
        "        valid = counts > 0\n",
        "        sums = seg_vals.sum(dim=1)\n",
        "        avg_values[valid, seg_idx] = sums[valid] / counts[valid]\n",
        "\n",
        "    for seg_idx in range(num_segments_r):\n",
        "        lower = pos_edges_scaled[:, seg_idx].unsqueeze(1)\n",
        "        upper = pos_edges_scaled[:, seg_idx + 1].unsqueeze(1)\n",
        "        seg_mask = (D >= lower) & (D <= upper) & mask_pos\n",
        "        seg_vals = torch.where(seg_mask, D, torch.zeros_like(D))\n",
        "        counts = seg_mask.sum(dim=1)\n",
        "        valid = counts > 0\n",
        "        sums = seg_vals.sum(dim=1)\n",
        "        avg_values[valid, num_segments_l + seg_idx] = sums[valid] / counts[valid]\n",
        "\n",
        "    # Add a zero value as the first segment (reserved for out-of-range positions)\n",
        "    avg_values = torch.cat([\n",
        "        torch.zeros((avg_values.size(0), 1), dtype=avg_values.dtype, device=avg_values.device),\n",
        "        avg_values\n",
        "    ], dim=1)  # shape (B, num_segments + 1)\n",
        "\n",
        "    index_matrix = torch.zeros_like(D, dtype=torch.long)\n",
        "\n",
        "    for seg_idx in range(num_segments_l):\n",
        "        lower = neg_edges_scaled[:, seg_idx].unsqueeze(1)\n",
        "        upper = neg_edges_scaled[:, seg_idx + 1].unsqueeze(1)\n",
        "        seg_mask = (D >= lower) & (D < upper) & mask_neg\n",
        "        index_matrix[seg_mask] = seg_idx + 1\n",
        "\n",
        "    for seg_idx in range(num_segments_r):\n",
        "        lower = pos_edges_scaled[:, seg_idx].unsqueeze(1)\n",
        "        upper = pos_edges_scaled[:, seg_idx + 1].unsqueeze(1)\n",
        "        seg_mask = (D >= lower) & (D <= upper) & mask_pos\n",
        "        index_matrix[seg_mask] = num_segments_l + seg_idx + 1\n",
        "\n",
        "    # Convert segment indices to binary\n",
        "    binary_matrix = ((index_matrix.unsqueeze(-1) >> torch.arange(num_bits - 1, -1, -1, device=device)) & 1).to(torch.int8)\n",
        "    binary_matrix = binary_matrix.reshape(B, num_bits * N)\n",
        "\n",
        "    # Compress binary representation\n",
        "    packed_binary_matrix = packbits_pytorch(binary_matrix)\n",
        "    og_shape_bin = binary_matrix.shape\n",
        "\n",
        "    compressed_batch = {\n",
        "        'outliers': non_zero_elements_tensor,\n",
        "        'avg_values': avg_values,\n",
        "        'packed_binary_matrix': packed_binary_matrix,\n",
        "        'og_shape_bin': og_shape_bin\n",
        "    }\n",
        "\n",
        "    return compressed_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "tsePDfImsAcV"
      },
      "outputs": [],
      "source": [
        "def orthoQuant_encode_1bit(D, lower_limit, upper_limit):\n",
        "    \"\"\"\n",
        "    Encodes vectors using a single segment per dimension (num_bits = 1).\n",
        "    For each vector, elements outside the specified percentile range are discarded,\n",
        "    and the average is computed over the remaining elements.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    D : torch.Tensor of shape (n, d)\n",
        "        Rotated vectors to be compressed.\n",
        "    lower_limit : int\n",
        "        Lower index of the segment to use (percentile).\n",
        "    upper_limit : int\n",
        "        Upper index of the segment to use (percentile).\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    A dictionary containing:\n",
        "        - 'non_zero_elements': elements outside the [l, r] range\n",
        "        - 'avg_values': per-vector average of the central segment, broadcast to shape (n, d)\n",
        "        - 'packed_binary_matrix': packed boolean mask of the central segment\n",
        "        - 'og_shape_bin': original shape before packing\n",
        "    \"\"\"\n",
        "    n, d = D.shape\n",
        "    device = D.device\n",
        "\n",
        "    # Sort each row to compute percentiles\n",
        "    sorted_D, _ = torch.sort(D, dim=1)\n",
        "    l = sorted_D[:, lower_limit]  # (n,)\n",
        "    r = sorted_D[:, upper_limit]  # (n,)\n",
        "\n",
        "    # Ensure [l, r] defines a valid range\n",
        "    l = torch.where(l > 0, -r.abs(), l)\n",
        "    r = torch.where(r < 0, l.abs(), r)\n",
        "\n",
        "    mask_l = D < l.unsqueeze(1)\n",
        "    mask_r = D > r.unsqueeze(1)\n",
        "\n",
        "    # Count initial number of elements outside the range per row\n",
        "    counts_l = mask_l.sum(dim=1)\n",
        "    counts_r = mask_r.sum(dim=1)\n",
        "\n",
        "    # Use the counts from the first vector as the expected count\n",
        "    expected_l = counts_l[0]\n",
        "    expected_r = counts_r[0]\n",
        "\n",
        "    # Expand masks to match expected counts if necessary\n",
        "    mask_l = expand_mask_side(mask_l, counts_l, expected_l, sorted_D, D, side='left')\n",
        "    mask_r = expand_mask_side(mask_r, counts_r, expected_r, sorted_D, D, side='right')\n",
        "\n",
        "    # Verify that all rows now have the same number of masked elements\n",
        "    counts_l = mask_l.sum(dim=1)\n",
        "    counts_r = mask_r.sum(dim=1)\n",
        "\n",
        "    assert torch.all(counts_l == expected_l), \"Uniformity in left mask not achieved\"\n",
        "    assert torch.all(counts_r == expected_r), \"Uniformity in right mask not achieved\"\n",
        "\n",
        "    mask_og = mask_l | mask_r\n",
        "\n",
        "    # Ensure all vectors have the same number of out-of-range values\n",
        "    counts = mask_og.sum(dim=1)\n",
        "    assert torch.all(counts == counts[0]), f\"Vectors do not have the same number of out-of-range values! {counts}\"\n",
        "\n",
        "    # Store out-of-range values as \"non_zero_elements\"\n",
        "    non_zero_elements_tensor = D[mask_og].view(n, -1)\n",
        "\n",
        "    # In-range segment\n",
        "    mask_seg = ~mask_og          # (n, d)\n",
        "    segment = D * mask_seg       # (n, d), zeros will not affect the average\n",
        "    avg_values = segment.sum(dim=1, keepdim=True) / mask_seg.sum(dim=1, keepdim=True)  # (n, 1)\n",
        "\n",
        "    # Add a column of zeros at the beginning\n",
        "    zero_col = torch.zeros_like(avg_values)\n",
        "    avg_values = torch.cat([zero_col, avg_values], dim=1)  # (n, 2)\n",
        "\n",
        "    # Encode the binary mask\n",
        "    binary_matrix = mask_seg.to(torch.uint8)  # (n, d)\n",
        "    og_shape_bin = binary_matrix.shape\n",
        "    packed_binary_matrix = packbits_pytorch(binary_matrix)\n",
        "\n",
        "    compressed_batch = {\n",
        "        'outliers': non_zero_elements_tensor,\n",
        "        'avg_values': avg_values,\n",
        "        'packed_binary_matrix': packed_binary_matrix,\n",
        "        'og_shape_bin': og_shape_bin\n",
        "    }\n",
        "\n",
        "    return compressed_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tG5wx5CErHWb"
      },
      "outputs": [],
      "source": [
        "def packbits_pytorch(unpacked, num_bits=8):\n",
        "    \"\"\"\n",
        "    Packs a boolean tensor into uint8, equivalent to np.packbits.\n",
        "    `unpacked`: boolean tensor of size (n, m * num_bits)\n",
        "    Returns a uint8 tensor of size (n, m)\n",
        "    \"\"\"\n",
        "    device = unpacked.device\n",
        "    n, total_bits = unpacked.shape\n",
        "    assert total_bits % num_bits == 0, \"The total number of bits must be divisible by num_bits.\"\n",
        "\n",
        "    m = total_bits // num_bits\n",
        "    unpacked = unpacked.view(n, m, num_bits).to(torch.uint8)\n",
        "    bits = torch.tensor([1 << i for i in range(num_bits - 1, -1, -1)], device=device, dtype=torch.uint8)\n",
        "    packed = torch.sum(unpacked * bits, dim=-1)\n",
        "    return packed.to(dtype=torch.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p5HLBhH2rSEg"
      },
      "outputs": [],
      "source": [
        "# Function to expand the mask per row if the count does not match\n",
        "def expand_mask_side(mask_side, counts_side, expected, sorted_D, D, side='left'):\n",
        "    B, N = mask_side.shape\n",
        "    mask_expanded = mask_side.clone()\n",
        "\n",
        "    # Rows that need expansion\n",
        "    rows_to_expand = (counts_side != expected).nonzero(as_tuple=True)[0]\n",
        "    if len(rows_to_expand) == 0:\n",
        "        return mask_expanded  # No rows to expand\n",
        "\n",
        "    diffs = (expected - counts_side[rows_to_expand]).tolist()  # differences per row\n",
        "\n",
        "    # For each row to expand, obtain additional indices according to the side\n",
        "    # The maximum number of elements to add is max(diffs)\n",
        "    max_diff = max(diffs)\n",
        "\n",
        "    # Create a matrix with relative indices to add: shape (max_diff,)\n",
        "    offsets = torch.arange(max_diff, device=D.device)\n",
        "\n",
        "    if side == 'left':\n",
        "        # Indices to add: lower_limit + 1 + offset, vectorized\n",
        "        base_idx = lower_limit + 1\n",
        "        idx_to_add = base_idx + offsets.unsqueeze(0)  # shape (1, max_diff)\n",
        "        # For each row, only up to diffs[i] elements are desired\n",
        "        # For safety, clamp indices to < N\n",
        "        idx_to_add = torch.clamp(idx_to_add, max=N-1)\n",
        "    else:\n",
        "        # Indices to add: upper_limit - 1 - offset\n",
        "        base_idx = upper_limit - 1\n",
        "        idx_to_add = base_idx - offsets.unsqueeze(0)\n",
        "        idx_to_add = torch.clamp(idx_to_add, min=0)\n",
        "\n",
        "    # Repeat idx_to_add for all rows to expand: shape (num_rows, max_diff)\n",
        "    idx_to_add = idx_to_add.repeat(len(rows_to_expand), 1)\n",
        "\n",
        "    # For each row, limit the number of elements to add according to diffs\n",
        "    # Create a boolean mask to avoid adding extra elements\n",
        "    diffs_tensor = torch.tensor(diffs, device=D.device).unsqueeze(1)  # (num_rows, 1)\n",
        "    valid_mask = offsets.unsqueeze(0) < diffs_tensor  # (num_rows, max_diff)\n",
        "\n",
        "    # Extract the sorted values to be added: shape (num_rows, max_diff)\n",
        "    rows_idx = rows_to_expand.unsqueeze(1).expand(-1, max_diff)\n",
        "    vals_to_add = sorted_D[rows_idx, idx_to_add]\n",
        "\n",
        "    # Now add only the valid values by creating a mask for each row in D:\n",
        "    for i, row in enumerate(rows_to_expand):\n",
        "        vals = vals_to_add[i][valid_mask[i]]\n",
        "        # Instead of looping per value, broadcasting can be used to mark the mask:\n",
        "        # mask_expanded[row] = mask_expanded[row] | ((D[row].unsqueeze(1) == vals).any(dim=1))\n",
        "        # But for pure PyTorch, we use:\n",
        "        mask_expanded[row] = mask_expanded[row] | torch.isin(D[row], vals)\n",
        "\n",
        "    return mask_expanded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ctV9jyiPqSwe"
      },
      "outputs": [],
      "source": [
        "def find_concavity_changes(array, slope_threshold=1.0, atol=1e-2):\n",
        "    \"\"\"\n",
        "    Finds the points where the slope is equal to ±45 degrees, indicating concavity changes.\n",
        "\n",
        "    Parameters:\n",
        "        array (torch.Tensor): One-dimensional (flattened) tensor.\n",
        "        slope_threshold (float): Target slope value (default is 1.0 for 45 degrees).\n",
        "        atol (float): Tolerance to consider a slope as equal to the target.\n",
        "\n",
        "    Returns:\n",
        "        list: Indices where the slope is approximately ±slope_threshold.\n",
        "    \"\"\"\n",
        "    if array.dim() != 1:\n",
        "        raise ValueError(\"The tensor must be one-dimensional (flattened).\")\n",
        "\n",
        "    downsample_factor = max(1,int(len(array)/(2**11)))\n",
        "\n",
        "    # Calculate the necessary padding size to make the array divisible\n",
        "    padding_size = (downsample_factor - len(array) % downsample_factor) % downsample_factor\n",
        "\n",
        "    # Perform padding with zeros or replicate the last value\n",
        "    if padding_size > 0:\n",
        "        padding = torch.zeros(padding_size)  # Padding with zeros\n",
        "        array_padded = torch.cat((array, padding))\n",
        "    else:\n",
        "        array_padded = array\n",
        "\n",
        "    # Perform downsampling\n",
        "    downsampled_array = array_padded.view(-1, downsample_factor).mean(dim=1)\n",
        "\n",
        "    # Calculate dx based on the maximum value of the array\n",
        "    #dx = 10**(math.floor(math.log10(torch.max(torch.abs(array)).item())) - 2)\n",
        "    # Ensure the tensor is on the correct device before calling .item()\n",
        "    dx = 10**(math.floor(math.log10(torch.max(torch.abs(array)).cpu().item())) - 2)\n",
        "\n",
        "    # Compute the first derivative using vectorized finite differences\n",
        "    first_derivative = (downsampled_array[1:] - downsampled_array[:-1]) / dx\n",
        "\n",
        "    def find_indices(atol):\n",
        "        condition = (\n",
        "            (torch.abs(first_derivative - slope_threshold) <= atol) |\n",
        "            (torch.abs(first_derivative + slope_threshold) <= atol)\n",
        "        )\n",
        "        return torch.nonzero(condition).squeeze(1).tolist()\n",
        "\n",
        "    def ensure_two_elements(atol_initial, atol_max, step_size):\n",
        "        atol = atol_initial\n",
        "        while atol <= atol_max:\n",
        "            slope_indices = find_indices(atol)\n",
        "            if len(slope_indices) >= 2:\n",
        "                return slope_indices\n",
        "            atol += step_size  # Increase tolerance\n",
        "        return slope_indices  # Return best option\n",
        "\n",
        "    # Search for indices with the initial tolerance\n",
        "    slope_indices = ensure_two_elements(atol_initial=1e-6, atol_max=1, step_size=1e-1)\n",
        "\n",
        "    # If not enough indices are found, apply an alternative strategy\n",
        "    if len(slope_indices) < 2:\n",
        "        print(\"Warning: Less than 2 indices found. You may need to adjust your parameters.\")\n",
        "        # You can return default values or continue execution as needed\n",
        "\n",
        "    # Adjust the indices to correspond to the original array (considering downsampling)\n",
        "    adjusted_indices = [i * downsample_factor for i in slope_indices]\n",
        "\n",
        "\n",
        "    first_curve = adjusted_indices[0]\n",
        "    second_curve = adjusted_indices[-1]\n",
        "\n",
        "\n",
        "    return first_curve, second_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qtCbaMYwrbpo"
      },
      "outputs": [],
      "source": [
        "def estimate_global_concavity_thresholds(\n",
        "    vectors: torch.Tensor,\n",
        "    sample_size: int = 5000,\n",
        "    seed: int = None\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Estimates average lower and upper thresholds based on concavity changes\n",
        "    from a random sample of vectors.\n",
        "\n",
        "    Args:\n",
        "        vectors (Tensor): Tensor of shape (N, D) containing N vectors.\n",
        "        sample_size (int): Number of vectors to sample.\n",
        "        seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]: Average lower and upper concavity change thresholds.\n",
        "    \"\"\"\n",
        "    N = vectors.size(0)\n",
        "    sample_size = min(sample_size, N)\n",
        "\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    indices = torch.randperm(N)[:sample_size]\n",
        "\n",
        "    lower_limits = []\n",
        "    upper_limits = []\n",
        "\n",
        "    for idx in indices:\n",
        "        sorted_vec = torch.sort(vectors[idx])[0]\n",
        "        lower, upper = find_concavity_changes(sorted_vec)\n",
        "        lower_limits.append(lower)\n",
        "        upper_limits.append(upper)\n",
        "\n",
        "    avg_lower = float(torch.tensor(lower_limits, dtype=torch.float32).mean())\n",
        "    avg_upper = float(torch.tensor(upper_limits, dtype=torch.float32).mean())\n",
        "\n",
        "    return int(avg_lower), int(avg_upper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gfvdcPflrqa9"
      },
      "outputs": [],
      "source": [
        "def orthoQuant_encode_in_batches(dataset, lower_limit, upper_limit, num_bits, batch_size):\n",
        "    \"\"\"\n",
        "    Processes a set of vectors using orthoQuant_encode_optimized in batches.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset: tensor of shape (num_vectors, dim)\n",
        "    - lower_limit: lower index for segmentation\n",
        "    - upper_limit: upper index for segmentation\n",
        "    - num_bits: number of bits per segment index\n",
        "    - batch_size: batch size to use\n",
        "\n",
        "    Returns:\n",
        "    A dictionary with the concatenated fields:\n",
        "    - non_zero_elements: tensor of shape (total_vectors, K)\n",
        "    - avg_values: tensor of shape (total_vectors, num_segments + 1)\n",
        "    - packed_binary_matrix: tensor of shape (total_vectors, compressed_dim)\n",
        "    - og_shape_bin: tuple with the original binary shape before `packbits`\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    device = dataset.device\n",
        "    total_vectors = dataset.shape[0]\n",
        "\n",
        "    # Initialize lists to accumulate results\n",
        "    all_outliers = []\n",
        "    all_avg_values = []\n",
        "    all_packed_binaries = []\n",
        "\n",
        "    for i in range(0, total_vectors, batch_size):\n",
        "        batch = dataset[i:i + batch_size]\n",
        "        if num_bits == 1:\n",
        "            compressed = orthoQuant_encode_1bit(batch, lower_limit, upper_limit)\n",
        "        else:\n",
        "            compressed = orthoQuant_encode(batch, lower_limit, upper_limit, num_bits)\n",
        "\n",
        "        all_outliers.append(compressed['outliers'].detach())\n",
        "        all_avg_values.append(compressed['avg_values'].detach())\n",
        "        all_packed_binaries.append(compressed['packed_binary_matrix'].detach())\n",
        "\n",
        "        if i == 0:\n",
        "            og_shape_bin = compressed['og_shape_bin']  # assumed to be the same for all batches\n",
        "\n",
        "    result = {\n",
        "        'outliers': torch.cat(all_outliers, dim=0),\n",
        "        'avg_values': torch.cat(all_avg_values, dim=0),\n",
        "        'packed_binary_matrix': torch.cat(all_packed_binaries, dim=0),\n",
        "        'og_shape_bin': og_shape_bin\n",
        "    }\n",
        "\n",
        "    # Compute global mean per column and replace avg_values by this mean\n",
        "    mean_per_column = result['avg_values'].mean(dim=0)\n",
        "    result['avg_values'] = mean_per_column  # Shape changes from (total_vectors, d) to (d,)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BQsKO37QvBt-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "def get_size_in_bytes(obj):\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.element_size() * obj.numel()\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.nbytes\n",
        "    elif isinstance(obj, list) or isinstance(obj, tuple):\n",
        "        return sum(get_size_in_bytes(item) for item in obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        return sum(get_size_in_bytes(k) + get_size_in_bytes(v) for k, v in obj.items())\n",
        "    else:\n",
        "        return sys.getsizeof(obj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvrFEOF0sSj6"
      },
      "source": [
        "### Decoding Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tMKpT5u4vF2r"
      },
      "outputs": [],
      "source": [
        "def orthoQuant_decode_database(outliers, avg_values, packed_binary_matrix, og_shape_bin, num_bits):\n",
        "    \"\"\"\n",
        "    Reconstructs an approximation of the original tensor D using the\n",
        "    out-of-range values and the segment averages.\n",
        "\n",
        "    Args:\n",
        "        outliers (torch.Tensor): (B, k) containing original out-of-range values.\n",
        "        avg_values (torch.Tensor): (B, 2^num_bits) including a reserved zero value at index 0.\n",
        "        packed_binary_matrix (torch.Tensor): (B, m) encoded as uint8.\n",
        "        og_shape_bin (tuple): original shape of the binary matrix before packing.\n",
        "        num_bits (int): Number of bits used to encode indices.\n",
        "\n",
        "    Returns:\n",
        "        D_reconstructed (torch.Tensor): Approximation of the original tensor (B, N).\n",
        "    \"\"\"\n",
        "\n",
        "    device = packed_binary_matrix.device\n",
        "    B = packed_binary_matrix.size(0)\n",
        "    N = og_shape_bin[1] // num_bits\n",
        "\n",
        "    # Unpack the encoded indices\n",
        "    binary_matrix = unpackbits_pytorch(packed_binary_matrix, original_shape=og_shape_bin)\n",
        "    index_matrix = binary_matrix.view(B, N, num_bits)\n",
        "\n",
        "    indices = torch.zeros((B, N), dtype=torch.long, device=device)\n",
        "    for bit in range(num_bits):\n",
        "        indices = (indices << 1) | index_matrix[:, :, bit].to(torch.long)\n",
        "\n",
        "    # Initialize output tensor\n",
        "    D_reconstructed = torch.zeros((B, N), dtype=avg_values.dtype, device=device)\n",
        "\n",
        "    # Insert approximated in-range values (segmented)\n",
        "    D_reconstructed = avg_values.gather(1, indices)\n",
        "\n",
        "    # Insert original out-of-range values (index 0)\n",
        "    mask_out_of_range = (indices == 0)\n",
        "\n",
        "    counts_per_row = mask_out_of_range.sum(dim=1)\n",
        "\n",
        "    assert torch.all(mask_out_of_range.sum(dim=1) == outliers.size(1)), \\\n",
        "        \"Number of out-of-range elements does not match\"\n",
        "\n",
        "    D_reconstructed[mask_out_of_range] = outliers.flatten()\n",
        "\n",
        "    return D_reconstructed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m4woE_4VvFtP"
      },
      "outputs": [],
      "source": [
        "def orthoQuant_decode_indices(packed_binary_matrix, og_shape_bin, num_bits):\n",
        "    \"\"\"\n",
        "    Reconstructs an approximation of the original tensor D using the\n",
        "    out-of-range values and the averages per segment.\n",
        "\n",
        "    Args:\n",
        "        packed_binary_matrix (torch.Tensor): (B, m) encoded as uint8.\n",
        "        og_shape_bin (tuple): original shape of the binary matrix before packing.\n",
        "        num_bits (int): Number of bits used to encode indices.\n",
        "\n",
        "    Returns:\n",
        "        D_reconstructed (torch.Tensor): Approximation of the original tensor (B, N).\n",
        "    \"\"\"\n",
        "\n",
        "    device = packed_binary_matrix.device\n",
        "    B = packed_binary_matrix.size(0)\n",
        "    N = og_shape_bin[1] // num_bits\n",
        "\n",
        "    # Unpack the encoded indices\n",
        "    binary_matrix = unpackbits_pytorch(packed_binary_matrix, original_shape=og_shape_bin)\n",
        "    index_matrix = binary_matrix.view(B, N, num_bits)\n",
        "\n",
        "    indices = torch.zeros((B, N), dtype=torch.long, device=device)\n",
        "    for bit in range(num_bits):\n",
        "        indices = (indices << 1) | index_matrix[:, :, bit].to(torch.long)\n",
        "\n",
        "    return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gpKdSq8qwoFY"
      },
      "outputs": [],
      "source": [
        "def unpackbits_pytorch(packed, num_bits=8, original_shape=None):\n",
        "    \"\"\"\n",
        "    Unpacks a uint8 tensor into a boolean binary representation.\n",
        "    Inverse operation of packbits_pytorch_puro.\n",
        "    \"\"\"\n",
        "    device = packed.device\n",
        "    unpacked = ((packed.unsqueeze(-1) >> torch.arange(num_bits - 1, -1, -1, device=device)) & 1).to(torch.int8)\n",
        "    unpacked = unpacked.view(packed.size(0), -1)\n",
        "    if original_shape is not None:\n",
        "        # assert unpacked.numel() == original_shape[0] * original_shape[1]\n",
        "        unpacked = unpacked[:, :original_shape[1]]\n",
        "    return unpacked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qbOARu95vFzd"
      },
      "outputs": [],
      "source": [
        "def unpack_vector_indices(compressed_data, idx, num_bits):\n",
        "\n",
        "    packed_row = compressed_data['packed_binary_matrix'][idx]\n",
        "    device = packed_row.device\n",
        "    grouped_bits = 8\n",
        "    unpacked_row = ((packed_row.unsqueeze(-1) >> torch.arange(grouped_bits - 1, -1, -1, device=device)) & 1).to(torch.int8)\n",
        "    unpacked_bits = unpacked_row.view(-1, num_bits).to(torch.long)\n",
        "\n",
        "    indices = torch.zeros(unpacked_bits.size(0), dtype=torch.long, device=unpacked_row.device)\n",
        "    for bit in range(num_bits):\n",
        "        indices = (indices << 1) | unpacked_bits[:, bit]\n",
        "\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0fdIArUuezT"
      },
      "source": [
        "### Example for 6 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqRcKwxbubqW",
        "outputId": "b97a49a1-92a9-4d99-b4a7-e6697c94f236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lower_limit: 17, upper_limit: 364\n",
            "\n",
            "Total memory size of rotated base: 927227904 bytes (927.23 MB, 0.927228 GB)\n",
            "\n",
            "Total memory size of compressed rotated base: 260783406 bytes (260.78 MB, 0.260783 GB)\n",
            "\n",
            "Compression ratio: 71.87%\n"
          ]
        }
      ],
      "source": [
        "num_bits = 6\n",
        "batch_size = 100000\n",
        "lower_limit, upper_limit = estimate_global_concavity_thresholds(rotated_base, sample_size=5000, seed=24)\n",
        "print(f'lower_limit: {lower_limit}, upper_limit: {upper_limit}')\n",
        "\n",
        "rotated_base = rotated_base.to('cuda')\n",
        "compressed_rotated_base = orthoQuant_encode_in_batches(rotated_base, lower_limit, upper_limit, num_bits, batch_size)\n",
        "\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_base_{num_bits}b.pt')\n",
        "# torch.save(compressed_rotated_base, save_path)\n",
        "# compressed_rotated_base = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Size of the original rotated_base\n",
        "original_size = get_size_in_bytes(rotated_base)\n",
        "original_size_gb = original_size / 1e9\n",
        "original_size_mb = original_size / 1e6\n",
        "print(f\"\\nTotal memory size of rotated base: {original_size} bytes ({original_size_mb:.2f} MB, {original_size_gb:.6f} GB)\")\n",
        "\n",
        "# Size of the compressed rotated_base\n",
        "compressed_size = get_size_in_bytes(compressed_rotated_base)\n",
        "compressed_size_gb = compressed_size / 1e9\n",
        "compressed_size_mb = compressed_size / 1e6\n",
        "print(f\"\\nTotal memory size of compressed rotated base: {compressed_size} bytes ({compressed_size_mb:.2f} MB, {compressed_size_gb:.6f} GB)\")\n",
        "\n",
        "# Compression ratio\n",
        "compression_ratio = 100 * (1 - compressed_size / original_size)\n",
        "print(f\"\\nCompression ratio: {compression_ratio:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxlUCWqzsSqx",
        "outputId": "a69f90db-1729-485a-d4e8-24045428cf17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total memory size of rotated queries: 16896000 bytes (16.90 MB, 0.016896 GB)\n",
            "\n",
            "Total memory size of compressed rotated queries: 4752558 bytes (4.75 MB, 0.004753 GB)\n",
            "\n",
            "Compression ratio: 71.87%\n"
          ]
        }
      ],
      "source": [
        "rotated_queries = rotated_queries.to('cuda')\n",
        "compressed_rotated_queries = orthoQuant_encode_in_batches(rotated_queries, lower_limit, upper_limit, num_bits, batch_size)\n",
        "\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_queries_{num_bits}b.pt')\n",
        "# torch.save(compressed_rotated_queries, save_path)\n",
        "# compressed_rotated_queries = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Size of the original rotated_queries\n",
        "original_size = get_size_in_bytes(rotated_queries)\n",
        "original_size_gb = original_size / 1e9\n",
        "original_size_mb = original_size / 1e6\n",
        "print(f\"\\nTotal memory size of rotated queries: {original_size} bytes ({original_size_mb:.2f} MB, {original_size_gb:.6f} GB)\")\n",
        "\n",
        "# Size of the compressed rotated_queries\n",
        "compressed_size = get_size_in_bytes(compressed_rotated_queries)\n",
        "compressed_size_gb = compressed_size / 1e9\n",
        "compressed_size_mb = compressed_size / 1e6\n",
        "print(f\"\\nTotal memory size of compressed rotated queries: {compressed_size} bytes ({compressed_size_mb:.2f} MB, {compressed_size_gb:.6f} GB)\")\n",
        "\n",
        "# Compression ratio\n",
        "compression_ratio = 100 * (1 - compressed_size / original_size)\n",
        "print(f\"\\nCompression ratio: {compression_ratio:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR8UXrT5xRn3"
      },
      "source": [
        "## **4. Recall experiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-5Q_ne01RWM"
      },
      "source": [
        "### Full dot product functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iQYMQXH6xiFr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.func import vmap\n",
        "\n",
        "def orthoquant_dot_product(compressed_base, compressed_queries, idx_query, num_bits):\n",
        "    \"\"\"\n",
        "    Computes the normalized dot product between the compressed rotated query\n",
        "    (given by idx_query) and the entire compressed rotated base, using a single\n",
        "    average values vector (avg_values) shared for the entire base.\n",
        "\n",
        "    Returns:\n",
        "        sim: tensor of shape (n_base,) with the normalized dot products.\n",
        "    \"\"\"\n",
        "    # Decode the base\n",
        "    packed_binary_matrix = compressed_base['packed_binary_matrix']\n",
        "    og_shape_bin = compressed_base['og_shape_bin']\n",
        "    base_indices = orthoQuant_decode_indices(packed_binary_matrix, og_shape_bin, num_bits)\n",
        "    base_avg_values = compressed_base['avg_values']  # <-- vector of shape (d,)\n",
        "    base_outliers = compressed_base['outliers']  # (n_base, D)\n",
        "    n_base, D = base_indices.shape\n",
        "\n",
        "    # Decode the query\n",
        "    query_indices = unpack_vector_indices(compressed_queries, idx_query, num_bits)     # (D,)\n",
        "    query_avg_values = compressed_queries['avg_values']                    # (num_bins,)\n",
        "    query_outliers = compressed_queries['outliers'][idx_query]                # (D,)\n",
        "\n",
        "\n",
        "    # Expand query to match the base size\n",
        "    query_indices_exp = query_indices.unsqueeze(0).expand(n_base, -1)\n",
        "    query_outliers_exp = query_outliers.unsqueeze(0).expand(n_base, -1)\n",
        "\n",
        "    # Map values for base: use the same avg_values vector for all\n",
        "    base_vals = base_avg_values[base_indices]  # (n_base, D)\n",
        "\n",
        "    # Map values for the query\n",
        "    query_vals = query_avg_values[query_indices_exp]\n",
        "\n",
        "    # Replace zeros by outliers\n",
        "    base_vals[base_vals == 0] = base_outliers.flatten()\n",
        "    query_vals[query_vals == 0] = query_outliers_exp.flatten()\n",
        "\n",
        "    # Dot product and normalization\n",
        "    dot = (base_vals * query_vals).sum(dim=1)\n",
        "    norm_base = torch.norm(base_vals, dim=1)\n",
        "    norm_query = torch.norm(query_vals, dim=1)\n",
        "\n",
        "    #print('dot')\n",
        "\n",
        "    similarities = dot / (norm_base * norm_query + 1e-8)\n",
        "\n",
        "    return similarities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dyz_4vcbxRvW"
      },
      "outputs": [],
      "source": [
        "def recall_tables_by_k(\n",
        "    idx_query,\n",
        "    base,\n",
        "    queries,\n",
        "    compressed_base,\n",
        "    compressed_queries,\n",
        "    num_bits,\n",
        "    ks=[1, 5, 10, 15, 20, 25, 30],\n",
        "    Kprimes=[1, 2, 4, 8, 16, 32, 64, 128, 256, 1024],\n",
        "    eps=1e-8,\n",
        "    batch_size=100000\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes, for a given query, how many of the true top-k elements are present\n",
        "    in the top-K' elements after rotation (compressed space).\n",
        "\n",
        "    Returns:\n",
        "        recall_tables: dictionary {k: DataFrame with 1 row and columns [idx, K'=...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # === True similarity ===\n",
        "    q = queries[idx_query].unsqueeze(0)\n",
        "    dot = torch.matmul(q, base.T)\n",
        "    norm_q = torch.norm(q, dim=1, keepdim=True)\n",
        "    norm_base = torch.norm(base, dim=1, keepdim=True).T\n",
        "    sim = dot / (norm_q * norm_base + eps)\n",
        "    idx_real = torch.argsort(sim, dim=1, descending=True).squeeze(0)\n",
        "\n",
        "    # === Rotated similarity computed in batches ===\n",
        "    sim_rot_batches = []\n",
        "    num_vectors = compressed_base['outliers'].shape[0]\n",
        "\n",
        "    for i in range(0, num_vectors, batch_size):\n",
        "        batch_compressed_base = {\n",
        "            'outliers': compressed_base['outliers'][i:i + batch_size, :].clone(),\n",
        "            'avg_values': compressed_base['avg_values'].clone(),\n",
        "            'packed_binary_matrix': compressed_base['packed_binary_matrix'][i:i + batch_size, :].clone(),\n",
        "            'og_shape_bin': compressed_base['og_shape_bin'],\n",
        "        }\n",
        "\n",
        "        sim_batch = orthoquant_dot_product(\n",
        "            batch_compressed_base,\n",
        "            compressed_queries,\n",
        "            idx_query,\n",
        "            num_bits\n",
        "        )\n",
        "\n",
        "        sim_rot_batches.append(sim_batch)\n",
        "\n",
        "    sim_rot = torch.cat(sim_rot_batches, dim=0)\n",
        "    idx_rot = torch.argsort(sim_rot, descending=True)\n",
        "\n",
        "    # === Compute recall table for each k ===\n",
        "    recall_tables = {}\n",
        "\n",
        "    for k in ks:\n",
        "        top_k_real = set(idx_real[:k].tolist())\n",
        "        row = []\n",
        "\n",
        "        for Kp in Kprimes:\n",
        "            top_Kp_rot = set(idx_rot[:Kp].tolist())\n",
        "            recall = len(top_k_real.intersection(top_Kp_rot))\n",
        "            row.append(recall)\n",
        "\n",
        "        df = pd.DataFrame([row], columns=[f\"@'{Kp}\" for Kp in Kprimes])\n",
        "        df.insert(0, 'idx', idx_query)\n",
        "        recall_tables[k] = df\n",
        "\n",
        "    return recall_tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SuXk-mNIysQk"
      },
      "outputs": [],
      "source": [
        "def recall_k_for_all_queries(\n",
        "    base,\n",
        "    queries,\n",
        "    compressed_base,\n",
        "    compressed_queries,\n",
        "    num_bits,\n",
        "    ks=[1, 5, 10, 15, 20, 25, 30],\n",
        "    Kprimes=[1, 2, 4, 8, 16, 32, 64, 128, 256, 1024]\n",
        "):\n",
        "    \"\"\"\n",
        "    Applies recall_tables_by_k to all queries.\n",
        "\n",
        "    Returns:\n",
        "        dict_df_recalls: Dictionary with a DataFrame for each k, where columns are K' and rows are queries.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Dictionary of lists for each k\n",
        "    all_recalls_by_k = defaultdict(list)\n",
        "\n",
        "    for idx_query in tqdm(range(queries.shape[0]), desc=\"Calculating min_Ks and recall\"):\n",
        "        df_recalls = recall_tables_by_k(\n",
        "            idx_query,\n",
        "            base,\n",
        "            queries,\n",
        "            compressed_base,\n",
        "            compressed_queries,\n",
        "            num_bits,\n",
        "            ks=ks,\n",
        "            Kprimes=Kprimes\n",
        "        )\n",
        "\n",
        "        # Save each DataFrame in its corresponding list\n",
        "        for k in ks:\n",
        "            all_recalls_by_k[k].append(df_recalls[k])\n",
        "\n",
        "    # Concatenate results by k\n",
        "    dict_df_recalls = {\n",
        "        k: pd.concat(all_recalls_by_k[k], ignore_index=True)\n",
        "        for k in ks\n",
        "    }\n",
        "\n",
        "    return dict_df_recalls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQJ1pkjWyw-t"
      },
      "source": [
        "Little example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "kC73q2xOyyw5",
        "outputId": "efba5c8f-8a19-4095-cde1-3dcb713e368e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    1    1    1     1     1     1      1      1       1,\n",
              " 5:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    5     5     5     5      5      5       5,\n",
              " 10:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    8    10    10    10     10     10      10,\n",
              " 15:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    8    15    15    15     15     15      15,\n",
              " 20:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    8    16    20    20     20     20      20,\n",
              " 25:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    8    16    25    25     25     25      25,\n",
              " 30:    idx  @'1  @'2  @'4  @'8  @'16  @'32  @'64  @'128  @'256  @'1024\n",
              " 0    0    1    2    4    8    16    30    30     30     30      30}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_bits=6\n",
        "\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_base_{num_bits}b.pt')\n",
        "# compressed_rotated_base = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_queries_{num_bits}b.pt')\n",
        "# compressed_rotated_queries = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "subset_compressed_base = {}\n",
        "for key, value in compressed_rotated_base.items():\n",
        "    if isinstance(value, torch.Tensor) and value.ndim > 1:\n",
        "        subset_compressed_base[key] = value[:1000, :]\n",
        "    else:\n",
        "        subset_compressed_base[key] = value[:1000]\n",
        "\n",
        "\n",
        "subset_compressed_queries = {}\n",
        "for key, value in compressed_rotated_queries.items():\n",
        "     if isinstance(value, torch.Tensor) and value.ndim > 1:\n",
        "         subset_compressed_queries[key] = value[:100, :]\n",
        "     else:\n",
        "         subset_compressed_queries[key] = value[:100]\n",
        "\n",
        "# Evaluar para una sola query\n",
        "recalls = recall_tables_by_k(\n",
        "     idx_query=0,\n",
        "     base=base[:1000,:],\n",
        "     queries=queries[:100,:],\n",
        "     compressed_base=subset_compressed_base,\n",
        "     compressed_queries=subset_compressed_queries,\n",
        "     num_bits=num_bits\n",
        ")\n",
        "\n",
        "\n",
        "display(recalls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "oOUm1xUry-Nj",
        "outputId": "a4ccbeea-8b4d-46de-c512-92e89d08a126"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating min_Ks and recall: 100%|██████████| 100/100 [00:01<00:00, 92.35it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys([1, 5, 10, 15, 20, 25, 30])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dict_df_recalls =  recall_k_for_all_queries(\n",
        "                            base[:1000,:],\n",
        "                            queries[:100,:],\n",
        "                            subset_compressed_base,\n",
        "                            subset_compressed_queries,\n",
        "                            num_bits\n",
        "                        )\n",
        "\n",
        "\n",
        "display(dict_df_recalls.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8nZjx7o1aDU"
      },
      "source": [
        "### Subsampled dot product functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OhlX2OaM1aML"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.func import vmap\n",
        "import math\n",
        "\n",
        "def get_fixed_indices(D, k, seed=24):\n",
        "    \"\"\"\n",
        "    Returns a fixed subset of indices of size k within a space of dimension D,\n",
        "    generated using a fixed seed.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    return torch.randperm(D)[:k]\n",
        "\n",
        "def orthoquant_dot_product_subsampled(compressed_base, compressed_queries, idx_query, num_bits, subsample_factor):\n",
        "    \"\"\"\n",
        "    Computes the normalized dot product between the compressed rotated query\n",
        "    (given by idx_query) and the entire compressed rotated base, using a single\n",
        "    average values vector (avg_values) for the whole base.\n",
        "\n",
        "    Returns:\n",
        "        sim: tensor of shape (n_base,) with the normalized dot products.\n",
        "    \"\"\"\n",
        "    # Decode the base\n",
        "    packed_binary_matrix = compressed_base['packed_binary_matrix']\n",
        "    og_shape_bin = compressed_base['og_shape_bin']\n",
        "    base_indices = orthoQuant_decode_indices(packed_binary_matrix, og_shape_bin, num_bits)\n",
        "    base_avg_values = compressed_base['avg_values']  # <-- vector of shape (d,)\n",
        "    base_outliers = compressed_base['outliers']  # (n_base, D)\n",
        "    n_base, D = base_indices.shape\n",
        "\n",
        "    # Decode the query\n",
        "    query_indices = unpack_vector_indices(compressed_queries, idx_query, num_bits)     # (D,)\n",
        "    query_avg_values = compressed_queries['avg_values']                    # (num_bins,)\n",
        "    query_outliers = compressed_queries['outliers'][idx_query]                # (D,)\n",
        "\n",
        "    # Expand query to match base\n",
        "    query_indices_exp = query_indices.unsqueeze(0).expand(n_base, -1)\n",
        "    query_outliers_exp = query_outliers.unsqueeze(0).expand(n_base, -1)\n",
        "\n",
        "    # Map values for base: use the same avg_values vector for all\n",
        "    base_vals = base_avg_values[base_indices]  # (n_base, D)\n",
        "\n",
        "    # Map values for the query\n",
        "    query_vals = query_avg_values[query_indices_exp]\n",
        "\n",
        "    # Replace zeros with outliers\n",
        "    base_vals[base_vals == 0] = base_outliers.flatten()\n",
        "    query_vals[query_vals == 0] = query_outliers_exp.flatten()\n",
        "\n",
        "    # Get fixed dim/subsample_factor dimensions\n",
        "    k = D // subsample_factor\n",
        "    selected_dims = get_fixed_indices(D, k)\n",
        "\n",
        "    base_vals = base_vals[:, selected_dims]\n",
        "    query_vals = query_vals[:, selected_dims]\n",
        "\n",
        "    # Dot product and normalization\n",
        "    dot = (base_vals * query_vals).sum(dim=1)\n",
        "    norm_base = torch.norm(base_vals, dim=1)\n",
        "    norm_query = torch.norm(query_vals, dim=1)\n",
        "\n",
        "    #print('dot')\n",
        "\n",
        "    similarities = dot / (norm_base * norm_query + 1e-8)\n",
        "\n",
        "    return similarities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "MfELUo6X11dl"
      },
      "outputs": [],
      "source": [
        "def recall_tables_by_k_subsampled(\n",
        "    idx_query,\n",
        "    base,\n",
        "    queries,\n",
        "    compressed_base,\n",
        "    compressed_queries,\n",
        "    num_bits,\n",
        "    subsample_factor,\n",
        "    ks=[1, 5, 10, 15, 20, 25, 30],\n",
        "    Kprimes=[1, 2, 4, 8, 16, 32, 64, 128, 256, 1024],\n",
        "    eps=1e-8,\n",
        "    batch_size=100000\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes, for a given query, how many of the true top-k elements are present\n",
        "    in the rotated top-K' results.\n",
        "\n",
        "    Returns:\n",
        "        recall_tables: dictionary {k: DataFrame with 1 row and columns [idx, K'=...]}\n",
        "    \"\"\"\n",
        "\n",
        "    # === True similarity ===\n",
        "    q = queries[idx_query].unsqueeze(0)\n",
        "    dot = torch.matmul(q, base.T)\n",
        "    norm_q = torch.norm(q, dim=1, keepdim=True)\n",
        "    norm_base = torch.norm(base, dim=1, keepdim=True).T\n",
        "    sim = dot / (norm_q * norm_base + eps)\n",
        "    idx_real = torch.argsort(sim, dim=1, descending=True).squeeze(0)\n",
        "\n",
        "    # === Rotated similarity in batches ===\n",
        "    sim_rot_batches = []\n",
        "    num_vectors = compressed_base['outliers'].shape[0]\n",
        "\n",
        "    for i in range(0, num_vectors, batch_size):\n",
        "        batch_compressed_base = {\n",
        "            'outliers': compressed_base['outliers'][i:i + batch_size, :].clone(),\n",
        "            'avg_values': compressed_base['avg_values'].clone(),\n",
        "            'packed_binary_matrix': compressed_base['packed_binary_matrix'][i:i + batch_size, :].clone(),\n",
        "            'og_shape_bin': compressed_base['og_shape_bin'],\n",
        "        }\n",
        "\n",
        "        sim_batch = orthoquant_dot_product_subsampled(\n",
        "            batch_compressed_base,\n",
        "            compressed_queries,\n",
        "            idx_query,\n",
        "            num_bits,\n",
        "            subsample_factor\n",
        "        )\n",
        "\n",
        "        sim_rot_batches.append(sim_batch)\n",
        "\n",
        "    sim_rot = torch.cat(sim_rot_batches, dim=0)\n",
        "    idx_rot = torch.argsort(sim_rot, descending=True)\n",
        "\n",
        "    # === Compute recall table for each k ===\n",
        "    recall_tables = {}\n",
        "\n",
        "    for k in ks:\n",
        "        top_k_real = set(idx_real[:k].tolist())\n",
        "        row = []\n",
        "\n",
        "        for Kp in Kprimes:\n",
        "            top_Kp_rot = set(idx_rot[:Kp].tolist())\n",
        "            recall = len(top_k_real.intersection(top_Kp_rot))\n",
        "            row.append(recall)\n",
        "\n",
        "        df = pd.DataFrame([row], columns=[f\"@'{Kp}\" for Kp in Kprimes])\n",
        "        df.insert(0, 'idx', idx_query)\n",
        "        recall_tables[k] = df\n",
        "\n",
        "    return recall_tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nQELJR8A2HDe"
      },
      "outputs": [],
      "source": [
        "def recall_tables_by_k_subsampled_all_queries(\n",
        "    base,\n",
        "    queries,\n",
        "    compressed_base,\n",
        "    compressed_queries,\n",
        "    num_bits,\n",
        "    subsample_factor,\n",
        "    ks=[1, 5, 10, 15, 20, 25, 30],\n",
        "    Kprimes=[1, 2, 4, 8, 16, 32, 64, 128, 256, 1024]\n",
        "):\n",
        "    \"\"\"\n",
        "    Applies recall_tables_by_k_subsampled to all queries.\n",
        "\n",
        "    Returns:\n",
        "        dict_df_recalls: Dictionary with a DataFrame for each k, where columns are K' and rows are queries.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Dictionary of lists for each k\n",
        "    all_recalls_by_k = defaultdict(list)\n",
        "\n",
        "    for idx_query in tqdm(range(queries.shape[0]), desc=\"Calculating recalls\"):\n",
        "        df_recalls = recall_tables_by_k_subsampled(\n",
        "            idx_query,\n",
        "            base,\n",
        "            queries,\n",
        "            compressed_base,\n",
        "            compressed_queries,\n",
        "            num_bits,\n",
        "            subsample_factor,\n",
        "            ks=ks,\n",
        "            Kprimes=Kprimes\n",
        "        )\n",
        "\n",
        "        # Store each DataFrame in its corresponding list\n",
        "        for k in ks:\n",
        "            all_recalls_by_k[k].append(df_recalls[k])\n",
        "\n",
        "    # Concatenate results per k\n",
        "    dict_df_recalls = {\n",
        "        k: pd.concat(all_recalls_by_k[k], ignore_index=True)\n",
        "        for k in ks\n",
        "    }\n",
        "\n",
        "    return dict_df_recalls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4xRIrGw2Pex"
      },
      "source": [
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "OVu__Sxo2Pk-",
        "outputId": "f4063322-5579-43d5-a7a1-23a855ef9535"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating recalls: 100%|██████████| 100/100 [00:01<00:00, 93.21it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys([1, 5, 10, 15, 20, 25, 30])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dict_df_recalls_subsampled =  recall_tables_by_k_subsampled_all_queries(\n",
        "                            base[:1000,:],\n",
        "                            queries[:100,:],\n",
        "                            subset_compressed_base,\n",
        "                            subset_compressed_queries,\n",
        "                            num_bits,\n",
        "                            subsample_factor=2\n",
        "                        )\n",
        "\n",
        "\n",
        "display(dict_df_recalls_subsampled.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_F6fcO02d1O"
      },
      "source": [
        "### Full dot product experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMbDnvz72pNP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Assuming queries has shape (N, D)\n",
        "num_queries = queries.shape[0]\n",
        "\n",
        "# Randomly select 10,000 unique indices\n",
        "sample_indices = torch.randperm(num_queries)[:10000]\n",
        "\n",
        "# Optional: save the selected queries\n",
        "sampled_queries = queries[sample_indices]\n",
        "\n",
        "# sample_indices is a tensor of shape (10000,) that you can save\n",
        "save_path = os.path.join(results_dir, f'sampled_query_indices_10k.pt')\n",
        "torch.save(sample_indices, save_path)\n",
        "\n",
        "# To reload later:\n",
        "# save_path = os.path.join(results_dir, f'sampled_query_indices_10k.pt')\n",
        "# sample_indices = torch.load(save_path)\n",
        "# sampled_queries = queries[sample_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEo3jV-2eTE",
        "outputId": "c51401eb-afa5-404b-a0b1-3a288e6a50ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total memory size of rotated base: 927227904 bytes (927.23 MB, 0.927228 GB)\n",
            "\n",
            "Total memory size of compressed rotated base: 260783406 bytes (260.78 MB, 0.260783 GB)\n",
            "\n",
            "Compression ratio: 71.87%\n"
          ]
        }
      ],
      "source": [
        "num_bits = 6\n",
        "\n",
        "save_path = os.path.join(results_dir, f'sampled_query_indices_10k.pt')\n",
        "sample_indices = torch.load(save_path)\n",
        "sampled_queries = queries[sample_indices]\n",
        "\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_base_{num_bits}b.pt')\n",
        "# compressed_rotated_base = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "# save_path = os.path.join(results_dir, f'compressed_rotated_queries_{num_bits}b.pt')\n",
        "# compressed_rotated_queries = torch.load(save_path, map_location=torch.device('cpu'))\n",
        "\n",
        "subset_compressed_queries = {}\n",
        "for key, value in compressed_rotated_queries.items():\n",
        "    if isinstance(value, torch.Tensor) and value.ndim > 1:\n",
        "        subset_compressed_queries[key] = value[sample_indices, :]  # filas y todas las columnas\n",
        "    else:\n",
        "        subset_compressed_queries[key] = value  # copiar otros objetos tal cual\n",
        "\n",
        "\n",
        "# Size of the original rotated_base\n",
        "original_size = get_size_in_bytes(rotated_base)\n",
        "original_size_gb = original_size / 1e9\n",
        "original_size_mb = original_size / 1e6\n",
        "print(f\"\\nTotal memory size of rotated base: {original_size} bytes ({original_size_mb:.2f} MB, {original_size_gb:.6f} GB)\")\n",
        "\n",
        "# Size of the compressed rotated_base\n",
        "compressed_size = get_size_in_bytes(compressed_rotated_base)\n",
        "compressed_size_gb = compressed_size / 1e9\n",
        "compressed_size_mb = compressed_size / 1e6\n",
        "print(f\"\\nTotal memory size of compressed rotated base: {compressed_size} bytes ({compressed_size_mb:.2f} MB, {compressed_size_gb:.6f} GB)\")\n",
        "\n",
        "# Compression ratio\n",
        "compression_ratio = 100 * (1 - compressed_size / original_size)\n",
        "print(f\"\\nCompression ratio: {compression_ratio:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIng0RGn3bqU"
      },
      "outputs": [],
      "source": [
        "def move_compressed_data_to_device(compressed_data, device):\n",
        "    return {k: v.to(device=device) if torch.is_tensor(v) else v\n",
        "            for k, v in compressed_data.items()}\n",
        "\n",
        "device = 'cuda'\n",
        "compressed_rotated_base = move_compressed_data_to_device(compressed_rotated_base, device)\n",
        "subset_compressed_queries = move_compressed_data_to_device(subset_compressed_queries, device)\n",
        "\n",
        "dict_df_recalls =  recall_k_for_all_queries(\n",
        "                            base.to(device=device),\n",
        "                            sampled_queries.to(device=device),\n",
        "                            compressed_rotated_base,\n",
        "                            subset_compressed_queries,\n",
        "                            num_bits\n",
        "                        )\n",
        "\n",
        "display(dict_df_recalls.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UIOlQIjA_D7Z"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(results_dir, f'dict_df_recalls_{num_bits}b.pt')\n",
        "#torch.save(dict_df_recalls, save_path)\n",
        "dict_df_recalls = torch.load(save_path, map_location=torch.device('cpu'), weights_only=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgpLevuF2egI"
      },
      "source": [
        "### Subsampled dot product experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-sY5Arn2ema"
      },
      "outputs": [],
      "source": [
        "num_bits = 6\n",
        "\n",
        "dict_df_recalls =  recall_tables_by_k_subsampled_all_queries(\n",
        "                            base.to(device=device),\n",
        "                            sampled_queries.to(device=device),\n",
        "                            compressed_rotated_base,\n",
        "                            subset_compressed_queries,\n",
        "                            num_bits,\n",
        "                            subsample_factor=2\n",
        "                        )\n",
        "\n",
        "display(dict_df_recalls.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "H_E6qeC5_frs"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(results_dir, f'sampled_dict_df_recalls_{num_bits}b.pt')\n",
        "#torch.save(dict_df_recalls, save_path)\n",
        "dict_df_recalls = torch.load(save_path, map_location=torch.device('cpu'), weights_only=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8xNXHw14w5i"
      },
      "source": [
        "## **5. Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMbzRKj96pe7"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "JE65gZVv4xH4"
      },
      "outputs": [],
      "source": [
        "def load_and_clean_dict_df_recalls(results_dir, filename):\n",
        "    \"\"\"\n",
        "    Loads a .pt file containing a dictionary of DataFrames,\n",
        "    removes the 'idx' column if it exists, and cleans quotes from column names.\n",
        "\n",
        "    Args:\n",
        "        results_dir (str): Path to the directory where the file is located.\n",
        "        filename (str): Name of the .pt file containing the dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, pd.DataFrame]: A cleaned dictionary of DataFrames.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import torch\n",
        "    import pandas as pd  # Ensure pandas is available\n",
        "\n",
        "    save_path = os.path.join(results_dir, filename)\n",
        "    dict_df_recalls = torch.load(save_path, weights_only=False, map_location=torch.device('cpu'))\n",
        "\n",
        "    for k in dict_df_recalls:\n",
        "        df = dict_df_recalls[k]\n",
        "\n",
        "        # Remove 'idx' column if it exists\n",
        "        if 'idx' in df.columns:\n",
        "            df = df.drop(columns=['idx'])\n",
        "\n",
        "        # Clean quotation marks from column names\n",
        "        clean_cols = {\n",
        "            col: str(col).replace(\"'\", \"\").replace('\"', \"\") for col in df.columns\n",
        "        }\n",
        "\n",
        "        dict_df_recalls[k] = df.rename(columns=clean_cols)\n",
        "\n",
        "    return dict_df_recalls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "sGxP3Qke48BY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def recall_at_k_table(results_dir, filename, num_bits):\n",
        "    \"\"\"\n",
        "    Compares recall@k values (e.g., recall@1) across three files with different subsampling levels.\n",
        "\n",
        "    Args:\n",
        "        results_dir (str): Directory where the results are stored.\n",
        "        filename (str): Name of the file containing the recall data.\n",
        "        num_bits (int): Number of bits used in the filename (not used in this function directly).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Comparative recall@k table.\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    dict_df = load_and_clean_dict_df_recalls(results_dir, filename)\n",
        "\n",
        "    for k in dict_df.keys():\n",
        "        df = dict_df[k]\n",
        "        data[k] = df.mean() / k  # Compute average recall and normalize by k\n",
        "\n",
        "    result_df = pd.DataFrame(data).T  # rows = different subsampling settings, columns = @k\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1bA67Bu6r6A"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdekmPG7AsI3"
      },
      "source": [
        "Full dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "7Rb41uvV6s-y",
        "outputId": "307f54ae-b19d-4110-aba9-6cc59167c9e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"@1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3220303652271362,\n        \"min\": 0.033326666666666664,\n        \"max\": 0.9201,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9201,\n          0.19927999999999998,\n          0.039988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3267143812478478,\n        \"min\": 0.06665666666666667,\n        \"max\": 0.9734,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9734,\n          0.39726,\n          0.079976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.335367553557382,\n        \"min\": 0.13331333333333334,\n        \"max\": 0.99,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.99,\n          0.7773,\n          0.159952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3093993283834025,\n        \"min\": 0.2665866666666667,\n        \"max\": 0.996,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.996,\n          0.9867000000000001,\n          0.31980000000000003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19465858741955006,\n        \"min\": 0.53241,\n        \"max\": 0.9988,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9988,\n          0.99716,\n          0.637884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@32\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009072035607777498,\n        \"min\": 0.9743933333333333,\n        \"max\": 0.9998,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9998,\n          0.9994999999999999,\n          0.992008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@64\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006813729836566347,\n        \"min\": 0.99812,\n        \"max\": 0.9999,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9999,\n          0.99986,\n          0.998552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@128\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00026696384234889013,\n        \"min\": 0.9992166666666668,\n        \"max\": 0.9999,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9999,\n          0.9997199999999999,\n          0.9992166666666668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@256\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0001139983291439759,\n        \"min\": 0.9997,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          0.9999100000000001,\n          0.9997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@1024\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2717317277246063e-05,\n        \"min\": 0.9999666666666667,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.999995,\n          0.9999666666666667,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fad35997-a618-4625-843d-3ad9dc47da46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>@1</th>\n",
              "      <th>@2</th>\n",
              "      <th>@4</th>\n",
              "      <th>@8</th>\n",
              "      <th>@16</th>\n",
              "      <th>@32</th>\n",
              "      <th>@64</th>\n",
              "      <th>@128</th>\n",
              "      <th>@256</th>\n",
              "      <th>@1024</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.920100</td>\n",
              "      <td>0.973400</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.996000</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>0.999800</td>\n",
              "      <td>0.999900</td>\n",
              "      <td>0.999900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.199280</td>\n",
              "      <td>0.397260</td>\n",
              "      <td>0.777300</td>\n",
              "      <td>0.986700</td>\n",
              "      <td>0.997160</td>\n",
              "      <td>0.999500</td>\n",
              "      <td>0.999860</td>\n",
              "      <td>0.999900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.199740</td>\n",
              "      <td>0.398860</td>\n",
              "      <td>0.786020</td>\n",
              "      <td>0.992880</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>0.999670</td>\n",
              "      <td>0.999720</td>\n",
              "      <td>0.999910</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.066633</td>\n",
              "      <td>0.133253</td>\n",
              "      <td>0.266420</td>\n",
              "      <td>0.531833</td>\n",
              "      <td>0.968467</td>\n",
              "      <td>0.997707</td>\n",
              "      <td>0.999313</td>\n",
              "      <td>0.999607</td>\n",
              "      <td>0.999873</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.049985</td>\n",
              "      <td>0.099965</td>\n",
              "      <td>0.199895</td>\n",
              "      <td>0.399605</td>\n",
              "      <td>0.791845</td>\n",
              "      <td>0.996185</td>\n",
              "      <td>0.999000</td>\n",
              "      <td>0.999470</td>\n",
              "      <td>0.999820</td>\n",
              "      <td>0.999995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.039988</td>\n",
              "      <td>0.079976</td>\n",
              "      <td>0.159952</td>\n",
              "      <td>0.319800</td>\n",
              "      <td>0.637884</td>\n",
              "      <td>0.992008</td>\n",
              "      <td>0.998552</td>\n",
              "      <td>0.999336</td>\n",
              "      <td>0.999764</td>\n",
              "      <td>0.999984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.033327</td>\n",
              "      <td>0.066657</td>\n",
              "      <td>0.133313</td>\n",
              "      <td>0.266587</td>\n",
              "      <td>0.532410</td>\n",
              "      <td>0.974393</td>\n",
              "      <td>0.998120</td>\n",
              "      <td>0.999217</td>\n",
              "      <td>0.999700</td>\n",
              "      <td>0.999967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fad35997-a618-4625-843d-3ad9dc47da46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fad35997-a618-4625-843d-3ad9dc47da46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fad35997-a618-4625-843d-3ad9dc47da46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2dfd1334-f761-478a-911a-c5f37ca6126d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dfd1334-f761-478a-911a-c5f37ca6126d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2dfd1334-f761-478a-911a-c5f37ca6126d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1a7c23fc-834f-4f68-a310-7c1811fa51b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a7c23fc-834f-4f68-a310-7c1811fa51b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          @1        @2        @4        @8       @16       @32       @64  \\\n",
              "1   0.920100  0.973400  0.990000  0.996000  0.998800  0.999800  0.999900   \n",
              "5   0.199280  0.397260  0.777300  0.986700  0.997160  0.999500  0.999860   \n",
              "10  0.099930  0.199740  0.398860  0.786020  0.992880  0.998800  0.999670   \n",
              "15  0.066633  0.133253  0.266420  0.531833  0.968467  0.997707  0.999313   \n",
              "20  0.049985  0.099965  0.199895  0.399605  0.791845  0.996185  0.999000   \n",
              "25  0.039988  0.079976  0.159952  0.319800  0.637884  0.992008  0.998552   \n",
              "30  0.033327  0.066657  0.133313  0.266587  0.532410  0.974393  0.998120   \n",
              "\n",
              "        @128      @256     @1024  \n",
              "1   0.999900  1.000000  1.000000  \n",
              "5   0.999900  1.000000  1.000000  \n",
              "10  0.999720  0.999910  1.000000  \n",
              "15  0.999607  0.999873  1.000000  \n",
              "20  0.999470  0.999820  0.999995  \n",
              "25  0.999336  0.999764  0.999984  \n",
              "30  0.999217  0.999700  0.999967  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_bits = 6\n",
        "filename = f'dict_df_recalls_{num_bits}b.pt'\n",
        "results_df = recall_at_k_table(results_dir, filename, num_bits)\n",
        "\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4g9KXTTAuXa"
      },
      "source": [
        "Sampled dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "NBTHR0c7AkaJ",
        "outputId": "d6ae99ab-85fa-4dc5-db31-a78192160cd9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"@1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22730729478360626,\n        \"min\": 0.03252666666666667,\n        \"max\": 0.6625,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.6625,\n          0.17786,\n          0.038832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26124320292606423,\n        \"min\": 0.06420333333333333,\n        \"max\": 0.7926,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7926,\n          0.33064,\n          0.076472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2778066904632384,\n        \"min\": 0.12449333333333333,\n        \"max\": 0.8822,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8822,\n          0.56386,\n          0.14754\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2638028663296329,\n        \"min\": 0.23418,\n        \"max\": 0.9334,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9334,\n          0.76376,\n          0.27449999999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20622492649717977,\n        \"min\": 0.4149233333333333,\n        \"max\": 0.9689,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9689,\n          0.8739800000000001,\n          0.475536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@32\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12478370751549325,\n        \"min\": 0.6448166666666667,\n        \"max\": 0.9855,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9855,\n          0.9356199999999999,\n          0.697508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@64\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06925810992566997,\n        \"min\": 0.8051200000000001,\n        \"max\": 0.9939,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9939,\n          0.9689,\n          0.8366800000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@128\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03565676645329413,\n        \"min\": 0.90045,\n        \"max\": 0.9975,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9975,\n          0.9856999999999999,\n          0.9177719999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@256\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01662796889304093,\n        \"min\": 0.9540133333333334,\n        \"max\": 0.9991,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9991,\n          0.9945,\n          0.9629439999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"@1024\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0026243489623505502,\n        \"min\": 0.99292,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.9994,\n          0.994448\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-84a0f24a-0bc9-4d36-be61-d6c39641c82a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>@1</th>\n",
              "      <th>@2</th>\n",
              "      <th>@4</th>\n",
              "      <th>@8</th>\n",
              "      <th>@16</th>\n",
              "      <th>@32</th>\n",
              "      <th>@64</th>\n",
              "      <th>@128</th>\n",
              "      <th>@256</th>\n",
              "      <th>@1024</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.792600</td>\n",
              "      <td>0.882200</td>\n",
              "      <td>0.933400</td>\n",
              "      <td>0.968900</td>\n",
              "      <td>0.985500</td>\n",
              "      <td>0.99390</td>\n",
              "      <td>0.997500</td>\n",
              "      <td>0.999100</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.177860</td>\n",
              "      <td>0.330640</td>\n",
              "      <td>0.563860</td>\n",
              "      <td>0.763760</td>\n",
              "      <td>0.873980</td>\n",
              "      <td>0.935620</td>\n",
              "      <td>0.96890</td>\n",
              "      <td>0.985700</td>\n",
              "      <td>0.994500</td>\n",
              "      <td>0.999400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.093240</td>\n",
              "      <td>0.179740</td>\n",
              "      <td>0.332710</td>\n",
              "      <td>0.561570</td>\n",
              "      <td>0.758160</td>\n",
              "      <td>0.870500</td>\n",
              "      <td>0.93508</td>\n",
              "      <td>0.969850</td>\n",
              "      <td>0.987650</td>\n",
              "      <td>0.998530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.063560</td>\n",
              "      <td>0.123727</td>\n",
              "      <td>0.234273</td>\n",
              "      <td>0.419033</td>\n",
              "      <td>0.653887</td>\n",
              "      <td>0.809927</td>\n",
              "      <td>0.90190</td>\n",
              "      <td>0.953020</td>\n",
              "      <td>0.979940</td>\n",
              "      <td>0.997460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.048200</td>\n",
              "      <td>0.094550</td>\n",
              "      <td>0.180920</td>\n",
              "      <td>0.331665</td>\n",
              "      <td>0.554565</td>\n",
              "      <td>0.752190</td>\n",
              "      <td>0.86862</td>\n",
              "      <td>0.935370</td>\n",
              "      <td>0.971345</td>\n",
              "      <td>0.996075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.038832</td>\n",
              "      <td>0.076472</td>\n",
              "      <td>0.147540</td>\n",
              "      <td>0.274500</td>\n",
              "      <td>0.475536</td>\n",
              "      <td>0.697508</td>\n",
              "      <td>0.83668</td>\n",
              "      <td>0.917772</td>\n",
              "      <td>0.962944</td>\n",
              "      <td>0.994448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.032527</td>\n",
              "      <td>0.064203</td>\n",
              "      <td>0.124493</td>\n",
              "      <td>0.234180</td>\n",
              "      <td>0.414923</td>\n",
              "      <td>0.644817</td>\n",
              "      <td>0.80512</td>\n",
              "      <td>0.900450</td>\n",
              "      <td>0.954013</td>\n",
              "      <td>0.992920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84a0f24a-0bc9-4d36-be61-d6c39641c82a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84a0f24a-0bc9-4d36-be61-d6c39641c82a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84a0f24a-0bc9-4d36-be61-d6c39641c82a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f1844c66-8dd8-4938-abb2-1f53fa8ad4ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1844c66-8dd8-4938-abb2-1f53fa8ad4ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f1844c66-8dd8-4938-abb2-1f53fa8ad4ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_becc2358-0552-420e-95bd-38c5b861783d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_becc2358-0552-420e-95bd-38c5b861783d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          @1        @2        @4        @8       @16       @32      @64  \\\n",
              "1   0.662500  0.792600  0.882200  0.933400  0.968900  0.985500  0.99390   \n",
              "5   0.177860  0.330640  0.563860  0.763760  0.873980  0.935620  0.96890   \n",
              "10  0.093240  0.179740  0.332710  0.561570  0.758160  0.870500  0.93508   \n",
              "15  0.063560  0.123727  0.234273  0.419033  0.653887  0.809927  0.90190   \n",
              "20  0.048200  0.094550  0.180920  0.331665  0.554565  0.752190  0.86862   \n",
              "25  0.038832  0.076472  0.147540  0.274500  0.475536  0.697508  0.83668   \n",
              "30  0.032527  0.064203  0.124493  0.234180  0.414923  0.644817  0.80512   \n",
              "\n",
              "        @128      @256     @1024  \n",
              "1   0.997500  0.999100  1.000000  \n",
              "5   0.985700  0.994500  0.999400  \n",
              "10  0.969850  0.987650  0.998530  \n",
              "15  0.953020  0.979940  0.997460  \n",
              "20  0.935370  0.971345  0.996075  \n",
              "25  0.917772  0.962944  0.994448  \n",
              "30  0.900450  0.954013  0.992920  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_bits = 6\n",
        "filename = f'sampled_dict_df_recalls_{num_bits}b.pt'\n",
        "results_df = recall_at_k_table(results_dir, filename, num_bits)\n",
        "\n",
        "display(results_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zStrEIPq7cWN",
        "x-u8577tny6a",
        "XrgvRENZotk9",
        "-mlpwiCzo4bT",
        "k24bHgfdsKed",
        "TvrFEOF0sSj6",
        "N0fdIArUuezT",
        "fR8UXrT5xRn3",
        "s-5Q_ne01RWM",
        "G8nZjx7o1aDU",
        "P_F6fcO02d1O",
        "fgpLevuF2egI",
        "PMbzRKj96pe7"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00d14bb8e6074aeb9be2947ef8c5a050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a09ba370b0b49d596e08824d8f678e9",
            "placeholder": "​",
            "style": "IPY_MODEL_4d323be5b6e24e2fb652ff6215fa83f8",
            "value": " 1.14G/1.14G [00:20&lt;00:00, 57.4MB/s]"
          }
        },
        "1990a08c47f340149acea81d2322b55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2b7a04b43447bb8bdfe2836a5a0b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88b0e98dbb0f45db846e59d2ba4abeec",
              "IPY_MODEL_b0ce8f01c08046ed861da8f40a42dcf3",
              "IPY_MODEL_00d14bb8e6074aeb9be2947ef8c5a050"
            ],
            "layout": "IPY_MODEL_8ad5161fe6a046bc96b93e01b7ea85ec"
          }
        },
        "29fdf4c7be0d485ab81d007ef3dbd639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a09ba370b0b49d596e08824d8f678e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d323be5b6e24e2fb652ff6215fa83f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b0e98dbb0f45db846e59d2ba4abeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c982cd01cf684575913a63fc229aaa7e",
            "placeholder": "​",
            "style": "IPY_MODEL_1990a08c47f340149acea81d2322b55f",
            "value": "benchmark-dev-ccnews.h5: 100%"
          }
        },
        "8ad5161fe6a046bc96b93e01b7ea85ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ce8f01c08046ed861da8f40a42dcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fdf4c7be0d485ab81d007ef3dbd639",
            "max": 1137026048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfc9229ef05e420f98c53b15d367cbd3",
            "value": 1137026048
          }
        },
        "bfc9229ef05e420f98c53b15d367cbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c982cd01cf684575913a63fc229aaa7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
